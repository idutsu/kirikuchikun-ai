{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/idutsu/kirikuchikun-ai/blob/main/janome.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "UPsKVlwqQZez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install janome tqdm"
      ],
      "metadata": {
        "id": "56CtW08EYGfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import glob\n",
        "import html\n",
        "import csv\n",
        "from janome.tokenizer import Tokenizer\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "acBXGfnFYHl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "6anUu21JYGRB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: 形態素解析とパターン抽出の関数定義\n",
        "def extract_noun_particle_verb(directory, output_csv, max_articles=None):\n",
        "    \"\"\"\n",
        "    指定したディレクトリ内のすべてのJSONファイルから、\n",
        "    名詞 + 助詞「を」 + 動詞のパターンにマッチする部分を抽出し、\n",
        "    CSVファイルに書き出します。\n",
        "\n",
        "    Parameters:\n",
        "    - directory (str): JSONファイルが格納されているディレクトリのパス。\n",
        "    - output_csv (str): 出力するCSVファイルのパス。\n",
        "    - max_articles (int, optional): 処理する記事の最大数。Noneの場合は全ての記事を処理。\n",
        "    \"\"\"\n",
        "    # Janomeのトークナイザーを初期化\n",
        "    tokenizer = Tokenizer()\n",
        "\n",
        "    # JSONファイルの検索\n",
        "    json_files = glob.glob(os.path.join(directory, '**', '*.json'), recursive=True)\n",
        "\n",
        "    if not json_files:\n",
        "        print(f\"指定されたディレクトリ内にJSONファイルが見つかりません: {directory}\")\n",
        "        return\n",
        "\n",
        "    print(f\"見つかったJSONファイルの数: {len(json_files)}\")\n",
        "\n",
        "    # CSVファイルの準備\n",
        "    with open(output_csv, 'w', newline='', encoding='utf-8') as csvfile:\n",
        "        csv_writer = csv.writer(csvfile)\n",
        "        # ヘッダーの書き込み\n",
        "        csv_writer.writerow(['Article_ID', 'Title', 'Extracted_Phrase'])\n",
        "\n",
        "        articles_processed = 0\n",
        "\n",
        "        # 全JSONファイルをループ\n",
        "        for json_file in tqdm(json_files, desc=\"JSONファイルの処理\"):\n",
        "            try:\n",
        "                with open(json_file, 'r', encoding='utf-8') as f:\n",
        "                    for line in f:\n",
        "                        if max_articles is not None and articles_processed >= max_articles:\n",
        "                            print(\"\\n指定された記事数に達しました。処理を終了します。\")\n",
        "                            return\n",
        "\n",
        "                        try:\n",
        "                            article = json.loads(line)\n",
        "                        except json.JSONDecodeError as e:\n",
        "                            print(f\"JSONの解析エラー: {e}\")\n",
        "                            continue\n",
        "\n",
        "                        article_id = article.get('id', '')\n",
        "                        title = article.get('title', '')\n",
        "                        text = article.get('text', '')\n",
        "\n",
        "                        # HTMLエンティティのデコード\n",
        "                        decoded_text = html.unescape(text)\n",
        "\n",
        "                        # 形態素解析\n",
        "                        tokens = tokenizer.tokenize(decoded_text)\n",
        "\n",
        "                        # パターンマッチングのためにトークンリストを作成\n",
        "                        token_list = []\n",
        "                        for token in tokens:\n",
        "                            base_form = token.base_form\n",
        "                            part_of_speech = token.part_of_speech.split(',')[0]\n",
        "                            surface = token.surface\n",
        "                            token_list.append((surface, part_of_speech, base_form))\n",
        "\n",
        "                        # スライディングウィンドウでパターンを検索\n",
        "                        for i in range(len(token_list) - 2):\n",
        "                            first, second, third = token_list[i], token_list[i+1], token_list[i+2]\n",
        "\n",
        "                            # パターン: 名詞 + 助詞「を」 + 動詞\n",
        "                            if (first[1] == '名詞' and\n",
        "                                second[1] == '助詞' and second[0] == 'を' and\n",
        "                                third[1] == '動詞'):\n",
        "                                # 抽出したフレーズを結合\n",
        "                                phrase = first[0] + second[0] + third[0]\n",
        "                                # CSVに書き出し\n",
        "                                csv_writer.writerow([article_id, title, phrase])\n",
        "\n",
        "                        articles_processed += 1\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"ファイル {json_file} の処理中にエラーが発生しました: {e}\")\n",
        "                continue\n",
        "\n",
        "    print(f\"\\n処理が完了しました。抽出されたフレーズは {output_csv} に保存されています。\")\n"
      ],
      "metadata": {
        "id": "xwtLACXVXRvK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 関数の実行\n",
        "# JSONファイルが格納されているディレクトリのパスを指定\n",
        "json_directory = \"/content/drive/MyDrive/wikipedia_extracted_json\"  # 実際のディレクトリパスに変更してください\n",
        "\n",
        "# 出力するCSVファイルのパスを指定\n",
        "output_csv_path = \"/content/drive/MyDrive/extracted_phrases.csv\"  # 実際の保存先パスに変更してください\n",
        "\n",
        "# 処理する記事の最大数を指定（任意）\n",
        "max_articles_to_process = None  # Noneの場合は全ての記事を処理します。例: 10000\n",
        "\n",
        "# 関数を実行\n",
        "extract_noun_particle_verb(json_directory, output_csv_path, max_articles_to_process)"
      ],
      "metadata": {
        "id": "npgWO7B3YffZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}